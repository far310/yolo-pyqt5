import time
from PIL import Image
import os
import cv2
import numpy as np
import imagehash
from skimage.metrics import structural_similarity as ssim
from sklearn.metrics.pairwise import cosine_similarity


# ==== åæŠ•å½±å‡½æ•° ====
def project_to_world(u, v, mtx, dist, rvec, tvec):
    """
    åˆ©ç”¨å®Œæ•´çš„ç›¸æœºå†…å¤–å‚åæŠ•å½±é‡å»ºçœŸå®å°ºå¯¸ï¼ˆæ¨èï¼‰
    å°†åƒç´ åæ ‡ (u, v) åæŠ•å½±åˆ°ä¸–ç•Œåæ ‡ Z=0 å¹³é¢
    """
    uv = np.array([[[u, v]]], dtype=np.float32)
    undistorted = cv2.undistortPoints(uv, mtx, dist, P=mtx)
    uv_norm = undistorted[0][0]
    uv_dir = np.linalg.inv(mtx) @ np.array([uv_norm[0], uv_norm[1], 1.0])

    R, _ = cv2.Rodrigues(rvec)
    R_inv = np.linalg.inv(R)
    tvec = tvec.reshape(3, 1)

    s = -tvec[2][0] / (R_inv @ uv_dir)[2]
    world_point = R_inv @ (s * uv_dir - tvec)
    return world_point


# ==== äººå·¥æ ‡å®šæ‹Ÿåˆæ³• ====
def try_alpha(alpha):
    """
    åŸºäºå‡è®¾çš„ä¿®æ­£ï¼ˆç®€å•ï¼Œä½†ç²¾åº¦æœ‰é™ï¼‰
    äººå·¥æ ‡å®šæ‹Ÿåˆæ³•
        1.	æ‹¿ 5~10 ä¸ªä½ è®¤è¯†å®½åº¦çš„ç›®æ ‡ç‰©ï¼ˆæ¯”å¦‚æ±‰å ¡å®½åº¦æ˜¯ 10cmï¼‰ï¼›
        2.	æ¯ä¸ªç›®æ ‡ä½ éƒ½è®°å½•ä¸‹è¿™ä¸‰æ ·æ•°æ®ï¼š
        â€¢	çœŸå®å®½åº¦ï¼ˆcmï¼‰ï¼ˆä½ ç”¨å°ºå­é‡çš„ï¼‰
        â€¢	é¸Ÿç°å›¾ä¸­æµ‹é‡å®½åº¦ï¼ˆä½ ç®—å‡ºæ¥çš„ measured_widthï¼‰
        â€¢	bbox é«˜åº¦ï¼ˆåƒç´ ï¼‰ï¼ˆæ¥è‡ªå›¾åƒï¼‰
        3.	ç„¶åç”¨è¿™äº›æ•°æ®å»æ‹Ÿåˆ alpha ä½¿å¾—
    """
    total_error = 0
    data = [
        (100, 18.0, 10.0),
        (80, 16.0, 11.0),
        (120, 20.0, 9.5),
    ]
    for h, mw, rw in data:
        corrected = mw / (1 + alpha * h)
        error = abs(corrected - rw)
        total_error += error
    #  # ä»0.001åˆ°0.02ä¹‹é—´è¯•ä¸€åœˆ
    # best_alpha = min([round(a, 4) for a in np.linspace(0.001, 0.02, 100)],
    #                 key=try_alpha)
    # print(f"æœ€åˆé€‚çš„ alpha æ˜¯: {best_alpha}")
    return total_error


# ==== é«˜åº¦è¡¥å¿å°ºå¯¸è¯†åˆ«è®¡ç®— ====
def correct_size_with_height(measured_size, target_height, camera_height):
    """
    é«˜åº¦è¡¥å¿è®¡ç®—å…¬å¼
    # measured_sizeï¼šé€è§†å˜æ¢åæµ‹é‡å¾—åˆ°çš„å°ºå¯¸ï¼ˆå•ä½ï¼šcmï¼‰
    # target_heightï¼šç›®æ ‡ç‰©ä½“ç¦»å‚è€ƒå¹³é¢çš„é«˜åº¦ï¼ˆå•ä½ï¼šcmï¼‰ï¼Œå¦‚é¢åŒ…é«˜åº¦ + ç‰›è‚‰é¥¼åšåº¦/2
    # camera_heightï¼šç›¸æœºåˆ°å‚è€ƒå¹³é¢çš„å‚ç›´è·ç¦»ï¼ˆå•ä½ï¼šcmï¼‰
    """
    # è®¡ç®—è¡¥å¿æ¯”ä¾‹
    correction_ratio = 1 / (1 + (target_height / camera_height))

    # å®é™…å°ºå¯¸è¡¥å¿
    corrected_size = measured_size * correction_ratio

    return corrected_size


# ==== æ ‡å®šç›¸æœºç„¦è·ï¼ˆå•ä½ï¼šåƒç´ ï¼‰ ====
def calibrate_focal_length(w_pixel, real_distance_cm, real_width_cm):
    """
    æ ‡å®šç›¸æœºç„¦è·ï¼ˆå•ä½ï¼šåƒç´ ï¼‰
    å‚æ•°:
        w_pixel: æ ‡å®šå›¾ç‰‡ä¸­ç›®æ ‡çš„åƒç´ å®½åº¦
        real_distance_cm: æ‹ç…§æ—¶å®é™…ç›¸æœºåˆ°ç›®æ ‡çš„è·ç¦»ï¼ˆå•ä½ï¼šcmï¼‰
        real_width_cm: ç›®æ ‡å®é™…å®½åº¦ï¼ˆå•ä½ï¼šcmï¼‰
    è¿”å›:
        ç›¸æœºç­‰æ•ˆç„¦è· fï¼ˆå•ä½ï¼šåƒç´ ï¼‰
    """
    f = (w_pixel * real_distance_cm) / real_width_cm
    return f


# ==== å•ç›®æµ‹è· ====
def estimate_distance(focal_length, real_width_cm, w_pixel):
    """
    å•ç›®æµ‹è·
    å‚æ•°:
        focal_length: ç›¸æœºç„¦è·ï¼ˆåƒç´ ï¼‰
        real_width_cm: ç›®æ ‡å®é™…å®½åº¦ï¼ˆcmï¼‰
        w_pixel: æ£€æµ‹æ¡†åƒç´ å®½åº¦ï¼ˆpxï¼‰
    è¿”å›:
        ä¼°ç®—è·ç¦»ï¼ˆå•ä½ï¼šcmï¼‰
    """
    if w_pixel <= 0:
        return None  # é¿å…é™¤0é”™è¯¯
    distance = (focal_length * real_width_cm) / w_pixel
    return distance


# ==== ä¿®æ­£é¸Ÿç°å›¾ä¸­å› é«˜åº¦å¼•èµ·çš„å®½åº¦æµ‹é‡è¯¯å·® ====
def correct_width(measured_width_cm, bbox_height_px, alpha):
    """
    åŸºäºå‡è®¾çš„ä¿®æ­£ï¼ˆç®€å•ï¼Œä½†ç²¾åº¦æœ‰é™ï¼‰
    ä¿®æ­£é¸Ÿç°å›¾ä¸­å› é«˜åº¦å¼•èµ·çš„å®½åº¦æµ‹é‡è¯¯å·®ã€‚
    :param measured_width_cm: é€šè¿‡é¸Ÿç°å›¾è®¡ç®—å‡ºçš„å®½åº¦ï¼ˆå•ä½ï¼šcmï¼‰
    :param bbox_height_px: åœ¨åŸå§‹å›¾åƒä¸­ï¼Œè¯¥ç›®æ ‡çš„è¾¹ç•Œæ¡†é«˜åº¦ï¼ˆå•ä½ï¼šåƒç´ ï¼‰
    :param alpha: ç»éªŒç³»æ•°ï¼Œç”¨äºæ§åˆ¶ä¿®æ­£å¼ºåº¦
    :return: ä¿®æ­£åçš„ç‰©ç†å®½åº¦ï¼ˆå•ä½ï¼šcmï¼‰
    """
    corrected = measured_width_cm / (1 + alpha * bbox_height_px)
    return corrected


# ==== å›¾ç‰‡èƒŒæ™¯å¯¹æ¯”ç®—æ³• å¤šæ¡† ====
def detects_background_change_by_ssim(
    frame: np.ndarray,
    background: np.ndarray,
    detected_boxes: list,
    ssim_threshold: float = 0.94,
    resize_to: int = 120,
):
    """
    ä½¿ç”¨ SSIM æ£€æµ‹èƒŒæ™¯æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼ˆå¦‚å¼‚ç‰©ï¼‰

    å‚æ•°:
    - frame: å½“å‰å¸§å›¾åƒï¼ˆBGRï¼‰
    - background: èƒŒæ™¯å›¾åƒï¼ˆBGRï¼‰
    - detected_boxes: list of (x, y, w, h)ï¼Œå¤šä¸ªç›®æ ‡æ¡†ï¼ˆæ’é™¤æ£€æµ‹åŒºåŸŸï¼‰
    - ssim_threshold: SSIM ç›¸ä¼¼æ€§é˜ˆå€¼ï¼ˆè¶Šä½è¶Šæ•æ„Ÿï¼‰
    - resize_to: å›¾åƒç¼©æ”¾å°ºå¯¸ï¼ˆé»˜è®¤ 480ï¼‰

    è¿”å›:
    - ssim_score: SSIM åˆ†æ•°ï¼ˆ1 è¡¨ç¤ºå®Œå…¨ç›¸åŒï¼‰
    - is_different: True è¡¨ç¤ºæ£€æµ‹åˆ°å·®å¼‚ï¼ŒFalse è¡¨ç¤ºæ— å¼‚å¸¸
    - diff_mask: å·®å¼‚çƒ­åŠ›å›¾ï¼ˆå¯è§†åŒ–ç”¨ï¼‰
    """

    if frame.shape != background.shape:
        raise ValueError("frame å’Œ background å›¾åƒå°ºå¯¸ä¸ä¸€è‡´")

    # åˆ›å»ºå…¨ç™½ maskï¼Œæ’é™¤æ‰€æœ‰æ£€æµ‹æ¡†
    mask = np.ones(frame.shape[:2], dtype=np.uint8) * 255

    for box in detected_boxes:
        x, y, w, h = map(int, box)
        x1 = max(0, x - 10)
        y1 = max(0, y - 10)
        x2 = min(frame.shape[1], x + w + 10)
        y2 = min(frame.shape[0], y + h + 10)
        cv2.rectangle(mask, (x1, y1), (x2, y2), 0, -1)

    # ç°åº¦å›¾ + æ©ç 
    gray1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)

    gray1 = cv2.bitwise_and(gray1, gray1, mask=mask)
    gray2 = cv2.bitwise_and(gray2, gray2, mask=mask)

    # äºŒå€¼åŒ–
    _, gray1 = cv2.threshold(gray1, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    _, gray2 = cv2.threshold(gray2, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # ç¼©æ”¾
    gray1 = cv2.resize(gray1, (resize_to, resize_to))
    gray2 = cv2.resize(gray2, (resize_to, resize_to))

    # è®¡ç®— SSIM å·®å¼‚å›¾
    score = ssim(
        gray1,
        gray2,
        full=False,
        channel_axis=-1,  # å¤šé€šé“å›¾åƒ
        win_size=11,  # æ§åˆ¶æ„ŸçŸ¥å°ºåº¦
        gaussian_weights=True,  # ä½¿ç”¨é«˜æ–¯åŠ æƒ
        sigma=1.5,  # å¹³æ»‘ç¨‹åº¦
    )
    # diff_mask = (1 - diff_map) * 255
    # diff_mask = diff_mask.astype(np.uint8)

    is_different = score < ssim_threshold

    return score, is_different


# ==== å›¾ç‰‡èƒŒæ™¯å¯¹æ¯”ç®—æ³• ====
def detect_background_change_by_ssim(
    frame: np.ndarray,
    background: np.ndarray,
    detected_boxes: list,
    ssim_threshold: float = 0.94,
    resize_to: int = 480,
):
    """
    ä½¿ç”¨ SSIM æ£€æµ‹èƒŒæ™¯æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼ˆå¦‚å¼‚ç‰©ï¼‰

    å‚æ•°:
    - frame: å½“å‰å¸§å›¾åƒï¼ˆBGRï¼‰
    - background: èƒŒæ™¯å›¾åƒï¼ˆBGRï¼‰
    - detected_boxes: list of (x, y, w, h)ï¼Œç›®æ ‡åŒºåŸŸï¼ˆæ’é™¤æ£€æµ‹åŒºåŸŸï¼‰
    - ssim_threshold: SSIM ç›¸ä¼¼æ€§é˜ˆå€¼ï¼ˆè¶Šä½è¶Šæ•æ„Ÿï¼‰
    - resize_to: å›¾åƒç¼©æ”¾å°ºå¯¸ï¼ˆé»˜è®¤ 256ï¼‰

    è¿”å›:
    - ssim_score: SSIM åˆ†æ•°ï¼ˆ1 è¡¨ç¤ºå®Œå…¨ç›¸åŒï¼‰
    - is_different: True è¡¨ç¤ºæ£€æµ‹åˆ°å·®å¼‚ï¼ŒFalse è¡¨ç¤ºæ— å¼‚å¸¸
    - diff_mask: å·®å¼‚çƒ­åŠ›å›¾ï¼ˆå¯è§†åŒ–ç”¨ï¼‰
    """

    if frame.shape != background.shape:
        raise ValueError("frame å’Œ background å›¾åƒå°ºå¯¸ä¸ä¸€è‡´")

    # åˆ›å»ºæ’é™¤ç›®æ ‡åŒºåŸŸçš„ mask
    mask = np.ones(frame.shape[:2], dtype=np.uint8) * 255
    x, y, w, h = detected_boxes
    x, y, w, h = int(x), int(y), int(w), int(h)
    # ä¸Šä¸‹å·¦å³å„æ‰©å±•20åƒç´ 
    x_left_expanded = max(0, x - 10)
    x_right_expanded = min(frame.shape[1], x + w + 10)
    y_top_expanded = max(0, y - 10)
    y_bottom_expanded = min(frame.shape[0], y + h + 10)
    # ç»˜åˆ¶çŸ©å½¢
    cv2.rectangle(
        mask,
        (x_left_expanded, y_top_expanded),
        (x_right_expanded, y_bottom_expanded),
        0,
        -1,
    )

    # ç°åº¦å›¾ + æ©ç 
    gray1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)

    gray1 = cv2.bitwise_and(gray1, gray1, mask=mask)
    gray2 = cv2.bitwise_and(gray2, gray2, mask=mask)
    _, gray1 = cv2.threshold(gray1, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    _, gray2 = cv2.threshold(gray2, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    # ç¼©æ”¾
    gray1 = cv2.resize(gray1, (resize_to, resize_to))
    gray2 = cv2.resize(gray2, (resize_to, resize_to))

    # è®¡ç®— SSIM å·®å¼‚å›¾
    score, diff_map = ssim(
        gray1,
        gray2,
        full=True,
        channel_axis=-1,  # å¤šé€šé“å›¾åƒ
        win_size=11,  # æ§åˆ¶æ„ŸçŸ¥å°ºåº¦
        gaussian_weights=True,  # ä½¿ç”¨é«˜æ–¯åŠ æƒ
        sigma=1.5,  # å¹³æ»‘ç¨‹åº¦
    )
    diff_mask = (1 - diff_map) * 255  # åå‘å¤„ç†æˆâ€œå·®å¼‚å¼ºåº¦â€
    diff_mask = diff_mask.astype(np.uint8)

    is_different = score < ssim_threshold

    return score, is_different


# ==== å›¾ç‰‡èƒŒæ™¯å¯¹æ¯”ç®—æ³•ï¼Œæ•ˆæœå·® ====
def detect_background_change_from_image(
    frame: np.ndarray,
    background: np.ndarray,
    detected_boxes: list,
    phash_size: int = 480,
    threshold: int = 10,
):
    """
    æ£€æµ‹èƒŒæ™¯å›¾åƒæ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼ˆå¦‚æœ‰å¼‚ç‰©ï¼‰

    å‚æ•°:
    - frame: å½“å‰å¸§å›¾åƒï¼ˆBGR æ ¼å¼ï¼‰
    - background: èƒŒæ™¯å›¾åƒï¼ˆBGR æ ¼å¼ï¼‰
    - detected_boxes: list of (x, y, w, h)ï¼Œç›®æ ‡åŒºåŸŸï¼ˆæ’é™¤åŒºåŸŸï¼‰
    - phash_size: ç¼©æ”¾å°ºå¯¸ï¼ˆé»˜è®¤ 256 x 256ï¼‰
    - threshold: pHash å·®å¼‚é˜ˆå€¼ï¼ˆè¶Šå¤§è¶Šå®½æ¾ï¼‰

    è¿”å›:
    - hash_diff: pHash å·®å¼‚å€¼
    - is_different: True è¡¨ç¤ºèƒŒæ™¯å‘ç”Ÿå˜åŒ–ï¼ŒFalse è¡¨ç¤ºæ— å¼‚å¸¸
    """

    if frame is None or background is None:
        raise ValueError("å›¾åƒä¸èƒ½ä¸ºç©º")

    if frame.shape != background.shape:
        raise ValueError("frame å’Œ background å›¾åƒå°ºå¯¸ä¸ä¸€è‡´")

    # åˆ›å»ºé®ç½©ï¼šç›®æ ‡åŒºåŸŸä¸ºé»‘ï¼Œå…¶ä»–åŒºåŸŸä¸ºç™½
    # åˆ›å»ºé®ç½©å¹¶ç»˜åˆ¶æ‰©å±•åçš„çŸ©å½¢
    mask = np.ones(frame.shape[:2], dtype=np.uint8) * 255
    x, y, w, h = detected_boxes
    x, y, w, h = int(x), int(y), int(w), int(h)
    # ä¸Šä¸‹å·¦å³å„æ‰©å±•20åƒç´ 
    x_left_expanded = max(0, x - 10)
    x_right_expanded = min(frame.shape[1], x + w + 10)
    y_top_expanded = max(0, y - 10)
    y_bottom_expanded = min(frame.shape[0], y + h + 10)
    # ç»˜åˆ¶çŸ©å½¢
    cv2.rectangle(
        mask,
        (x_left_expanded, y_top_expanded),
        (x_right_expanded, y_bottom_expanded),
        0,
        -1,
    )
    # åº”ç”¨é®ç½©
    masked_frame = cv2.bitwise_and(frame, frame, mask=mask)
    masked_bg = cv2.bitwise_and(background, background, mask=mask)

    # è½¬ç°åº¦å¹¶ç¼©æ”¾ä¸º PIL å›¾åƒ
    def prepare(img, type):
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # gray = cv2.GaussianBlur(gray, (5, 5),0)
        _, gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        resized = cv2.resize(gray, (phash_size, phash_size))
        # if type==1:
        # cv2.imwrite("masked_frame.jpg", resized)
        # else:
        # cv2.imwrite("masked_bg.jpg", resized)
        return Image.fromarray(resized)

    img1 = prepare(masked_frame, 1)
    img2 = prepare(masked_bg, 2)

    # è®¡ç®— pHash
    hash1 = imagehash.phash(img1)
    hash2 = imagehash.phash(img2)
    hash_diff = hash1 - hash2

    is_different = hash_diff > threshold

    return hash_diff, is_different


# ==== å›¾ç‰‡èƒŒæ™¯å¯¹æ¯”ç®—æ³• åŠ äº†è£å‰ªèŒƒå›´ï¼Œæ•ˆæœå·® ====
def compare_background_phash(
    frame,
    background,
    detected_boxes=[],
    region_points=None,
    phash_size=256,
    threshold=6,
):
    """
    å¯¹æ¯”å½“å‰å›¾åƒä¸èƒŒæ™¯å›¾åƒåœ¨æŒ‡å®šåŒºåŸŸï¼ˆå¯å¤šè¾¹å½¢è£å‰ªï¼‰ã€æ’é™¤ç›®æ ‡æ¡†åçš„å·®å¼‚ï¼ˆpHashï¼‰

    å‚æ•°ï¼š
    - frame: å½“å‰å›¾åƒï¼ˆnp.ndarrayï¼‰
    - background: èƒŒæ™¯å›¾åƒï¼ˆnp.ndarrayï¼‰
    - detected_boxes: [(x, y, w, h), ...] éœ€è¦æ’é™¤çš„ç›®æ ‡æ¡†ï¼ˆé»‘è‰²é®ç½©ï¼‰
    - region_points: [[x1, y1], [x2, y2], [x3, y3], [x4, y4]] åŒºåŸŸå››è§’ç‚¹ï¼ˆå·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹ï¼‰
    - phash_size: pHash ç¼©æ”¾å°ºå¯¸ï¼ˆé»˜è®¤ 256ï¼‰
    - threshold: å·®å¼‚åˆ¤æ–­é˜ˆå€¼

    è¿”å›ï¼š
    - hash_diff: å·®å¼‚å€¼
    - is_different: True è¡¨ç¤ºæ£€æµ‹åˆ°å˜åŒ–
    """
    if frame.shape != background.shape:
        raise ValueError("å›¾åƒå°ºå¯¸ä¸ä¸€è‡´")

    h_img, w_img = frame.shape[:2]

    # 1. å¦‚æœç»™å®š region_pointsï¼Œè£å‰ªå‡ºè¯¥åŒºåŸŸï¼ˆä¸åšé€è§†ï¼‰
    if region_points is not None:
        mask_region = np.zeros((h_img, w_img), dtype=np.uint8)
        region_np = np.array([region_points], dtype=np.int32)
        cv2.fillPoly(mask_region, region_np, 255)
        frame = cv2.bitwise_and(frame, frame, mask=mask_region)
        background = cv2.bitwise_and(background, background, mask=mask_region)

    # 2. æ„å»ºé®ç½©ï¼šå…ˆå…¨ç™½ï¼Œç„¶ååœ¨ç›®æ ‡åŒºåŸŸå†…ç”»é»‘è‰²çŸ©å½¢
    mask = np.ones((h_img, w_img), dtype=np.uint8) * 255
    for x, y, w, h in detected_boxes:
        cv2.rectangle(mask, (x, y), (x + w, y + h), 0, -1)

    if region_points is not None:
        mask = cv2.bitwise_and(mask, mask_region)

    # 3. åº”ç”¨é®ç½©åˆ°ä¸¤å¼ å›¾
    masked_frame = cv2.bitwise_and(frame, frame, mask=mask)
    masked_bg = cv2.bitwise_and(background, background, mask=mask)

    # 4. å‡†å¤‡æ„ŸçŸ¥å“ˆå¸Œè¾“å…¥
    def prepare(img):
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        resized = cv2.resize(gray, (phash_size, phash_size))
        return Image.fromarray(resized)

    img1 = prepare(masked_frame)
    img2 = prepare(masked_bg)

    hash1 = imagehash.phash(img1)
    hash2 = imagehash.phash(img2)

    hash_diff = hash1 - hash2
    is_different = hash_diff > threshold

    return hash_diff, is_different


# ==== å›¾ç‰‡èƒŒæ™¯å¯¹æ¯”ç®—æ³• phash ä¼˜åŒ–å ====
def compares_background_phash(
    frame: np.ndarray,
    background: np.ndarray,
    detected_boxes: list,
    hash_size: int = 64,
    similarity_threshold: float = 0.65,
    resize_to: int = 256,
):
    """
    ä½¿ç”¨ pHash å¯¹æ¯”å›¾åƒä¸èƒŒæ™¯å›¾çš„å·®å¼‚ï¼ˆæ”¯æŒå¤šç›®æ ‡é®æŒ¡æ’é™¤ï¼‰

    å‚æ•°ï¼š
    - frame: å½“å‰å¸§å›¾åƒï¼ˆnp.ndarray, BGRï¼‰
    - background: èƒŒæ™¯å›¾åƒï¼ˆnp.ndarray, BGRï¼‰
    - detected_boxes: [(x, y, w, h), ...] è¦æ’é™¤çš„ç›®æ ‡æ¡†
    - hash_size: pHash å“ˆå¸Œå¤§å°ï¼ˆè¶Šå¤§è¶Šç²¾ç»†ï¼Œé»˜è®¤8ï¼Œå®é™…å›¾åƒå°†è¢«ç¼©æ”¾è‡³ hash_size*4ï¼‰
    - similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0~1ï¼Œè¶Šä½è¶Šæ•æ„Ÿï¼‰
    - resize_to: ä¸­é—´å¤„ç†æ—¶ç°åº¦å›¾ç¼©æ”¾å°ºå¯¸

    è¿”å›ï¼š
    - similarity: 0~1 ç›¸ä¼¼åº¦å¾—åˆ†ï¼Œ1 è¡¨ç¤ºå®Œå…¨ç›¸åŒ
    - is_different: æ˜¯å¦ä¸åŒï¼ˆå³ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼ï¼‰
    """
    print(f"æˆ‘å°±æ¥äº†0")
    if frame.shape != background.shape:
        raise ValueError("frame å’Œ background å›¾åƒå°ºå¯¸ä¸ä¸€è‡´")
    print(f"æˆ‘å°±æ¥äº†-1")
    # Step 1: åˆ›å»ºé®ç½©ï¼Œæ’é™¤ç›®æ ‡åŒºåŸŸ
    mask = np.ones(frame.shape[:2], dtype=np.uint8) * 255
    for box in detected_boxes:
        x, y, w, h = map(int, box)
        x1 = max(0, x - 10)
        y1 = max(0, y - 10)
        x2 = min(frame.shape[1], x + w + 10)
        y2 = min(frame.shape[0], y + h + 10)
        cv2.rectangle(mask, (x1, y1), (x2, y2), 0, -1)
    print(f"æˆ‘å°±æ¥äº†1")
    # Step 2: ç°åº¦ + æ©ç 
    gray1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)

    gray1 = cv2.bitwise_and(gray1, gray1, mask=mask)
    gray2 = cv2.bitwise_and(gray2, gray2, mask=mask)
    print(f"æˆ‘å°±æ¥äº†2")
    # Step 3: ç¼©æ”¾
    # _, gray1 = cv2.threshold(gray1, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    # _, gray2 = cv2.threshold(gray2, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    gray1 = cv2.resize(gray1, (resize_to, resize_to))
    gray2 = cv2.resize(gray2, (resize_to, resize_to))
    print(f"æˆ‘å°±æ¥äº†3")
    # Step 4: è½¬ä¸º PIL.Image åè®¡ç®—å“ˆå¸Œ
    img1 = Image.fromarray(gray1)
    img2 = Image.fromarray(gray2)
    print(f"æˆ‘å°±æ¥äº†4")
    hash1 = imagehash.phash(img1, hash_size=hash_size)
    hash2 = imagehash.phash(img2, hash_size=hash_size)
    print(f"æˆ‘å°±æ¥äº†5")
    # Step 5: è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆ0~1ï¼‰
    hamming_dist = hash1 - hash2
    max_bits = hash_size * hash_size
    similarity = 1 - (hamming_dist / max_bits)
    is_different = similarity < similarity_threshold

    return similarity, is_different


# ==== å›¾ç‰‡èƒŒæ™¯å¯¹æ¯”ç®—æ³• absdiff ====
def detects_background_change_by_absdiff_umat(
    frame: np.ndarray,
    background: np.ndarray,
    detected_boxes: list,
    diff_threshold: float = 25.0,
    pixel_change_ratio: float = 0.01,
    resize_to: int = 120,
):
    """
    ä½¿ç”¨ç»å¯¹å·®å¼‚æ£€æµ‹èƒŒæ™¯å˜åŒ–ï¼ˆæ”¯æŒ cv2.UMat ä»¥åŠ é€Ÿï¼‰

    å‚æ•°ï¼š
    - frame: å½“å‰å¸§å›¾åƒï¼ˆBGRï¼‰
    - background: èƒŒæ™¯å›¾åƒï¼ˆBGRï¼‰
    - detected_boxes: list of (x, y, w, h)
    - diff_threshold: å·®å¼‚å¼ºåº¦é˜ˆå€¼ï¼ˆåƒç´ çº§ï¼‰
    - pixel_change_ratio: å·®å¼‚åƒç´ æ¯”ä¾‹é˜ˆå€¼
    - resize_to: ç¼©æ”¾åè¾¹é•¿

    è¿”å›ï¼š
    - diff_ratio: å·®å¼‚åƒç´ æ¯”ä¾‹ï¼ˆ0~1ï¼‰
    - is_different: æ˜¯å¦æ£€æµ‹åˆ°å˜åŒ–
    """

    if frame.shape != background.shape:
        raise ValueError("frame å’Œ background å›¾åƒå°ºå¯¸ä¸ä¸€è‡´")

    # åˆ¤æ–­æ˜¯å¦æ”¯æŒ OpenCL
    use_umat = cv2.ocl.haveOpenCL() and cv2.ocl.useOpenCL()

    # åˆ›å»ºå…¨ç™½ maskï¼Œæ’é™¤æ‰€æœ‰ç›®æ ‡æ¡†ï¼ˆä½¿ç”¨æ™®é€š NumPyï¼‰
    mask = np.ones(frame.shape[:2], dtype=np.uint8) * 255
    for x, y, w, h in detected_boxes:
        x1, y1 = max(0, x - 10), max(0, y - 10)
        x2, y2 = min(frame.shape[1], x + w + 10), min(frame.shape[0], y + h + 10)
        cv2.rectangle(mask, (x1, y1), (x2, y2), 0, -1)

    # ç°åº¦å›¾ï¼ˆUMat æˆ–æ™®é€šï¼‰
    gray1 = cv2.cvtColor(cv2.UMat(frame) if use_umat else frame, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(
        cv2.UMat(background) if use_umat else background, cv2.COLOR_BGR2GRAY
    )

    # bitwise_and æ©ç ï¼ˆmask æ˜¯ numpy ç±»å‹ï¼Œå…¼å®¹ï¼‰
    gray1 = cv2.bitwise_and(gray1, gray1, mask=mask)
    gray2 = cv2.bitwise_and(gray2, gray2, mask=mask)

    # è½¬æ¢å› NumPy æ•°æ®ï¼Œè¿›è¡Œè£å‰ªæ“ä½œ
    if isinstance(gray1, cv2.UMat):
        gray1 = gray1.get()
    if isinstance(gray2, cv2.UMat):
        gray2 = gray2.get()

    coords = cv2.findNonZero(mask)
    x, y, w, h = cv2.boundingRect(coords)
    gray1 = gray1[y : y + h, x : x + w]
    gray2 = gray2[y : y + h, x : x + w]

    # ç¼©æ”¾åå†è½¬ä¸º UMatï¼ˆç”¨äºåŠ é€Ÿåç»­æ“ä½œï¼‰
    gray1 = cv2.resize(gray1, (resize_to, resize_to))
    gray2 = cv2.resize(gray2, (resize_to, resize_to))

    if use_umat:
        gray1 = cv2.UMat(gray1)
        gray2 = cv2.UMat(gray2)

    # å·®å¼‚å›¾
    diff = cv2.absdiff(gray1, gray2)

    # äºŒå€¼åŒ–
    _, diff_bin = cv2.threshold(diff, diff_threshold, 255, cv2.THRESH_BINARY)

    # ç»Ÿè®¡å·®å¼‚åƒç´ æ•°ï¼ˆéœ€è¦ä» UMat è½¬ä¸º NumPyï¼‰
    if isinstance(diff_bin, cv2.UMat):
        diff_bin = diff_bin.get()

    changed_pixels = np.count_nonzero(diff_bin)
    total_pixels = diff_bin.size
    ratio = changed_pixels / total_pixels

    return ratio, ratio > pixel_change_ratio


# ==== å›¾ç‰‡èƒŒæ™¯å¯¹æ¯”ç®—æ³• ä½¿ç”¨ç°åº¦ä½™å¼¦ç›¸ä¼¼åº¦æ£€æµ‹èƒŒæ™¯æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼Œé€Ÿåº¦å¿«ï¼Œç²¾åº¦é«˜====
def detects_background_change_by_cosine(
    frame: np.ndarray,
    background: np.ndarray,
    detected_boxes: list,
    similarity_threshold: float = 0.98,
    resize_to: int = 120,
):
    """
    ä½¿ç”¨ç°åº¦ä½™å¼¦ç›¸ä¼¼åº¦æ£€æµ‹èƒŒæ™¯æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼ˆå¦‚å¼‚ç‰©ï¼‰

    å‚æ•°ï¼š
    - frame, background: å½“å‰å¸§å’ŒèƒŒæ™¯å›¾ï¼ˆBGRï¼‰
    - detected_boxes: [(x,y,w,h), ...] ç›®æ ‡æ¡†ï¼ˆæ’é™¤åŒºåŸŸï¼‰
    - similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆè¶Šä½è¶Šæ•æ„Ÿï¼‰
    - resize_to: æ¯”è¾ƒå‰ç»Ÿä¸€ç¼©æ”¾å¤§å°

    è¿”å›ï¼š
    - similarity: 0~1ï¼Œç›¸ä¼¼åº¦å¾—åˆ†
    - is_different: True è¡¨ç¤ºæ£€æµ‹åˆ°å·®å¼‚
    """
    if frame.shape != background.shape:
        raise ValueError("å›¾åƒå°ºå¯¸ä¸ä¸€è‡´")

    # Step 1: æ„å»ºé®ç½©
    mask = np.ones(frame.shape[:2], dtype=np.uint8) * 255

    for box in detected_boxes:
        x, y, w, h = map(int, box)
        x1 = max(0, x - 10)
        y1 = max(0, y - 10)
        x2 = min(frame.shape[1], x + w + 10)
        y2 = min(frame.shape[0], y + h + 10)
        cv2.rectangle(mask, (x1, y1), (x2, y2), 0, -1)

    # Step 2: ç°åº¦ + æ©ç 
    gray1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)
    # æ‰¾é«˜äº®åŒºåŸŸï¼ˆé˜ˆå€¼å¯è°ƒï¼‰
    # _, mask1 = cv2.threshold(gray1, 210, 255, cv2.THRESH_BINARY)
    # # ä½¿ç”¨ inpaint ä¿®å¤
    # gray1 = cv2.inpaint(gray1, mask1, inpaintRadius=3, flags=cv2.INPAINT_TELEA)
    # _, mask2 = cv2.threshold(gray2, 210, 255, cv2.THRESH_BINARY)
    # # ä½¿ç”¨ inpaint ä¿®å¤
    # gray2 = cv2.inpaint(gray2, mask2, inpaintRadius=3, flags=cv2.INPAINT_TELEA)

    gray1 = cv2.bitwise_and(gray1, gray1, mask=mask)
    gray2 = cv2.bitwise_and(gray2, gray2, mask=mask)
    gray1 = remove_specular_reflection(gray1)
    gray2 = remove_specular_reflection(gray2)
    # gray1 = cv2.GaussianBlur(gray1, (15, 15), 3)
    # gray2 = cv2.GaussianBlur(gray2, (15, 15), 3)
    # _, gray1 = cv2.threshold(gray1, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    # _, gray2 = cv2.threshold(gray2, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    # Step 3: ç¼©æ”¾
    gray1 = cv2.resize(gray1, (resize_to, resize_to))
    gray2 = cv2.resize(gray2, (resize_to, resize_to))

    # Step 4: æ‰å¹³åŒ– + è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    vec1 = gray1.flatten().reshape(1, -1)
    vec2 = gray2.flatten().reshape(1, -1)
    similarity = cosine_similarity(vec1, vec2)[0][0]

    is_different = similarity < similarity_threshold
    return similarity, is_different


def remove_specular_reflection(
    gray: np.ndarray, threshold: int = 210, kernel_size: int = 5
):
    """
    å»é™¤ç°åº¦å›¾ä¸­çš„åå…‰åŒºåŸŸï¼ˆé«˜äº®åŒºï¼‰

    å‚æ•°:
    - gray: è¾“å…¥ç°åº¦å›¾ (np.ndarray)
    - threshold: æå–åå…‰åŒºåŸŸçš„äº®åº¦é˜ˆå€¼ï¼ˆé»˜è®¤240ï¼‰
    - kernel_size: æ›¿ä»£åå…‰åŒºåŸŸçš„ä¸­å€¼æ»¤æ³¢æ ¸å¤§å°

    è¿”å›:
    - gray_clean: å»é™¤åå…‰åçš„å›¾åƒ
    """
    # 1. æå–åå…‰åŒºåŸŸï¼ˆäº®åº¦ > thresholdï¼‰
    mask = cv2.inRange(gray, threshold, 255)

    # 2. æ‰©å±•åå…‰åŒºåŸŸï¼ˆå¯é€‰ï¼Œæé«˜é²æ£’æ€§ï¼‰
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    mask_dilated = cv2.dilate(mask, kernel, iterations=1)

    # 3. ä¸­å€¼æ»¤æ³¢æ•´ä¸ªå›¾åƒ
    median_filtered = cv2.medianBlur(gray, kernel_size)

    # 4. ç”¨éåå…‰åŒºåŸŸçš„åƒç´ æ›¿æ¢
    gray_clean = gray.copy()
    gray_clean[mask_dilated > 0] = median_filtered[mask_dilated > 0]

    return gray_clean


# ==== çº¿æ€§ æ‰¾è½®å»“ ====
def get_contour_dimensions(roi, yclFlag=True):
    """
    åœ¨æ„Ÿå…´è¶£åŒºåŸŸï¼ˆROIï¼‰ä¸­æ‰¾åˆ°æœ€å¤§çš„è½®å»“ï¼Œå¹¶è¿”å›å…¶ç²¾ç¡®çš„å®½åº¦å’Œé«˜åº¦ã€‚
    åŒæ—¶åœ¨ROIä¸Šç»˜åˆ¶ä¸¤æ¡è¾¹é•¿çº¿ï¼ˆæ°´å¹³çº¿å’Œå‚ç›´çº¿ï¼‰ã€‚

    Args:
        roi: åŒ…å«ç‰©ä½“çš„è£å‰ªåå›¾åƒã€‚

    Returns:
        ä¸€ä¸ªåŒ…å« (è½®å»“å®½åº¦, è½®å»“é«˜åº¦) çš„å…ƒç»„ï¼Œå¦‚æœæœªæ‰¾åˆ°è½®å»“åˆ™è¿”å› (None, None)ã€‚
    """
    print(f"get_contour_dimensions: æˆ‘è¿›æ¥äº† ==== {yclFlag} ")
    binary_image = None
    if yclFlag:
        # 1. å°†ROIè½¬æ¢ä¸ºç°åº¦å›¾å¹¶åº”ç”¨é˜ˆå€¼æ¥åˆ›å»ºäºŒå€¼å›¾åƒã€‚
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (9, 9), 0)
        _, binary_image = cv2.threshold(
            gray, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU
        )
    else:
        binary_image = roi
    # 2. åœ¨äºŒå€¼å›¾åƒä¸­æŸ¥æ‰¾æ‰€æœ‰è½®å»“ã€‚
    contours, _ = cv2.findContours(
        binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
    )

    if contours:
        # 3. é€šè¿‡é¢ç§¯æ‰¾åˆ°æœ€å¤§çš„è½®å»“ã€‚
        largest_contour = max(contours, key=cv2.contourArea)

        # 4. è·å–æœ€å¤§è½®å»“çš„ç´§å¯†è¾¹ç•Œæ¡†ã€‚
        x, y, contour_w, contour_h = cv2.boundingRect(largest_contour)

        # 5. åœ¨ROIä¸Šç»˜åˆ¶ä¸¤æ¡è¾¹é•¿çº¿ï¼ˆæ°´å¹³çº¿å’Œå‚ç›´çº¿ï¼‰ã€‚
        #    - æ°´å¹³çº¿ï¼šä» (x, y + contour_h//2) åˆ° (x + contour_w, y + contour_h//2)
        #    - å‚ç›´çº¿ï¼šä» (x + contour_w//2, y) åˆ° (x + contour_w//2, y + contour_h)
        cv2.line(
            roi,
            (x, y + contour_h // 2),
            (x + contour_w, y + contour_h // 2),
            (0, 255, 0),
            2,
        )  # ç»¿è‰²æ°´å¹³çº¿
        # cv2.line(roi, (x + contour_w // 2, y), (x + contour_w // 2, y + contour_h), (0, 0, 255), 2)    # çº¢è‰²å‚ç›´çº¿

        # å¯é€‰ï¼šç»˜åˆ¶æ•´ä¸ªè½®å»“ï¼ˆè°ƒè¯•ç”¨ï¼‰
        # cv2.drawContours(roi, [largest_contour], -1, (255, 0, 0), 1)

        return contour_w, contour_h

    return None, None


# ==== çº¿æ€§ æ‰¾è½®å»“ ä¼˜åŒ–ç‰ˆï¼Œä½†æ˜¯æœ‰æ—¶å€™è¯†åˆ«ä¸åˆ°çº¿é•¿ ====
def get_accurate_dimensions(roi, yclFlag=True):
    """
    ã€æ”¹é€ ç‰ˆã€‘ä¸€ä¸ªæ›´ç²¾ç¡®çš„ç‰©ä½“å°ºå¯¸è®¡ç®—å‡½æ•°ã€‚
    å­¦ä¹ äº†å‚è€ƒä»£ç ä¸­çš„ Cannyã€å½¢çŠ¶ç­›é€‰ å’Œ ç²¾ç¡®æµ‹é‡æ€æƒ³ã€‚

    Args:
        roi: åŒ…å«ç‰©ä½“çš„è£å‰ªå›¾åƒã€‚

    Returns:
        å¦‚æœæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç‰©ä½“ï¼Œåˆ™è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ï¼š
        {'width_px': å®½åº¦, 'height_px': é«˜åº¦, 'box_points': æ—‹è½¬æ¡†çš„å››ä¸ªè§’ç‚¹}
        å¦åˆ™è¿”å› Noneã€‚
    """
    print(f"get_accurate_dimensions: æˆ‘è¿›æ¥äº† ==== {yclFlag} ")
    if roi.size == 0:
        return None
    closed_canny = None
    if yclFlag:
        # 1. é¢„å¤„ç†ä¸è¾¹ç¼˜æ£€æµ‹ (å­¦ä¹ è‡ªå‚è€ƒä»£ç ä¸­çš„ Canny æ–¹æ³•)
        #    å¯¹äºè½®å»“åˆ†æ˜çš„ç‰©ä½“ï¼ŒCannyé€šå¸¸æ¯”ç®€å•çš„ç°åº¦é˜ˆå€¼æ›´æœ‰æ•ˆã€‚
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (9, 9), 0)
        _, blurred = cv2.threshold(
            blurred, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU
        )
        # cv2.imwrite("blurred.jpg", blurred)
        # Cannyè¾¹ç¼˜æ£€æµ‹ï¼Œå‚æ•°(50, 150)æ˜¯å¸¸ç”¨çš„èµ·å§‹å€¼ï¼Œå¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        canny = cv2.Canny(blurred, 20, 150)

        # ä½¿ç”¨å½¢æ€å­¦é—­è¿ç®—è¿æ¥æ–­å¼€çš„è¾¹ç¼˜ï¼Œä½¿è½®å»“æ›´å®Œæ•´
        kernel = np.ones((5, 5), np.uint8)
        closed_canny = cv2.morphologyEx(canny, cv2.MORPH_CLOSE, kernel, iterations=1)
    else:
        closed_canny = roi
    # å…ˆè†¨èƒ€åè…èš€ï¼ˆå¼€è¿ç®—çš„é€†æ“ä½œï¼Œå¯ä»¥å¢å¼ºè¾¹ç¼˜ï¼‰
    # closed_canny = cv2.dilate(closed_canny, kernel, iterations=1)
    # closed_canny = cv2.erode(closed_canny, kernel, iterations=1)
    # 2. æŸ¥æ‰¾å¹¶ç­›é€‰è½®å»“ (å­¦ä¹ è‡ªå‚è€ƒä»£ç ä¸­çš„ find_biggest_contour)
    contours, _ = cv2.findContours(
        closed_canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
    )
    # cv2.drawContours(roi, contours, -1, (255, 0, 0), 1)
    if contours:
        # 3. é€šè¿‡é¢ç§¯æ‰¾åˆ°æœ€å¤§çš„è½®å»“ã€‚
        largest_contour = max(contours, key=cv2.contourArea)

        # 4. è·å–æœ€å¤§è½®å»“çš„ç´§å¯†è¾¹ç•Œæ¡†ã€‚
        x, y, contour_w, contour_h = cv2.boundingRect(largest_contour)

        # 5. åœ¨ROIä¸Šç»˜åˆ¶ä¸¤æ¡è¾¹é•¿çº¿ï¼ˆæ°´å¹³çº¿å’Œå‚ç›´çº¿ï¼‰ã€‚
        #    - æ°´å¹³çº¿ï¼šä» (x, y + contour_h//2) åˆ° (x + contour_w, y + contour_h//2)
        #    - å‚ç›´çº¿ï¼šä» (x + contour_w//2, y) åˆ° (x + contour_w//2, y + contour_h)
        # cv2.line(roi, (x, y + contour_h // 2), (x + contour_w, y + contour_h // 2), (0, 255, 0), 2)  # ç»¿è‰²æ°´å¹³çº¿
        # cv2.line(roi, (x + contour_w // 2, y), (x + contour_w // 2, y + contour_h), (0, 0, 255), 2)    # çº¢è‰²å‚ç›´çº¿

        # å¯é€‰ï¼šç»˜åˆ¶æ•´ä¸ªè½®å»“ï¼ˆè°ƒè¯•ç”¨ï¼‰
        # cv2.drawContours(roi, [largest_contour], -1, (255, 0, 0), 1)
        return contour_w, contour_h

    return None, None


# ==== åœ†å½¢æ‰¾è½®å»“ ====
def get_circle_diameter_and_draw(roi, yclFlag=True):
    """
    ã€æœ€ç»ˆåœ†å½¢ç‰ˆã€‘åœ¨ROIä¸­æ‰¾åˆ°æœ€æ˜¾è‘—çš„åœ†å½¢ï¼Œç›´æ¥åœ¨ROIä¸ŠæŠŠå®ƒç”»å‡ºæ¥ï¼Œå¹¶è¿”å›å…¶ç›´å¾„ã€‚
    å‡½æ•°æ¥å£å’Œè¿”å›å€¼ä¸¥æ ¼æŒ‰ç…§æ‚¨çš„è¦æ±‚è®¾è®¡ã€‚

    Args:
        roi: åŒ…å«ç‰©ä½“çš„è£å‰ªå›¾åƒã€‚è¯¥å›¾åƒå°†è¢«ç›´æ¥ä¿®æ”¹ï¼ˆåœ¨ä¸Šé¢ç»˜å›¾ï¼‰ã€‚

    Returns:
        (ç›´å¾„, ç›´å¾„) å…ƒç»„ã€‚å¦‚æœæœªæ‰¾åˆ°åœ†å½¢åˆ™è¿”å› (None, None)ã€‚
    """
    if roi.size == 0:
        return None, None
    blurred = None
    # 1. é¢„å¤„ç†ï¼šç°åº¦åŒ–å’Œé«˜æ–¯æ¨¡ç³Š
    #    éœå¤«åœ†å˜æ¢å¯¹å™ªå£°æ•æ„Ÿï¼Œæ¨¡ç³Šå¤„ç†æ˜¯å¿…è¦æ­¥éª¤ã€‚
    if yclFlag:
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (15, 15), 3)
        _, blurred = cv2.threshold(
            blurred, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU
        )
    else:
        blurred = roi
    # cv2.imwrite("blurred.jpg", blurred)
    # ä½¿ç”¨å½¢æ€å­¦é—­è¿ç®—è¿æ¥æ–­å¼€çš„è¾¹ç¼˜ï¼Œä½¿è½®å»“æ›´å®Œæ•´
    # cv2.imwrite("blurred.jpg", blurred)
    circles = cv2.HoughCircles(
        blurred,
        cv2.HOUGH_GRADIENT,
        dp=1,  # ç´¯åŠ å™¨åˆ†è¾¨ç‡ä¸å›¾åƒç›¸åŒ(1)æˆ–æ›´é«˜(>1)
        minDist=30,  # åœ†ä¹‹é—´çš„æœ€å°è·ç¦»(æ ¹æ®å®é™…ç‰©ä½“é—´è·è°ƒæ•´)
        param1=100,  # Cannyè¾¹ç¼˜æ£€æµ‹é«˜é˜ˆå€¼(é™ä½ä»¥æ£€æµ‹å¼±è¾¹ç¼˜)
        param2=10,  # ç´¯åŠ å™¨é˜ˆå€¼(é™ä½ä»¥æ£€æµ‹æ›´å¤šåœ†)
        minRadius=50,  # æœ€å°åœ†åŠå¾„(æ ¹æ®å®é™…ç‰©ä½“å¤§å°è°ƒæ•´)
        maxRadius=180,  # æœ€å¤§åœ†åŠå¾„(0è¡¨ç¤ºä¸é™åˆ¶)
    )
    height, width = roi.shape[:2]
    if circles is not None and len(circles[0]) > 0:
        # 3. éå†æ‰€æœ‰åœ†ï¼Œæ‰¾å‡ºæœ€å¤§ç›´å¾„ä¸”ä¸è¶Šç•Œçš„åœ†
        valid_circles = []
        for c in circles[0]:
            x, y, r = map(int, np.round(c))
            if (
                x - r >= 0
                and y - r >= 0
                and x + r <= (width - 10)
                and y + r <= (height - 10)
            ):
                valid_circles.append((x, y, r))
        if valid_circles:
            # é€‰æœ€å¤§åŠå¾„çš„åœ†
            # x, y, r = max(valid_circles, key=lambda c: c[2])
            x, y, r = valid_circles[0]
            diameter = float(2 * r)
            # ç»˜åˆ¶åœ†å’Œåœ†å¿ƒ
            # cv2.circle(roi, (x, y), r, (0, 255, 0), 2)
            # cv2.circle(roi, (x, y), 3, (0, 0, 255), -1)
            return diameter, diameter
    # if circles is not None:
    # æ‰¾åˆ°åŠå¾„æœ€å¤§çš„åœ†ï¼ˆå³ç›´å¾„æœ€å¤§çš„åœ†ï¼‰
    # largest_circle = max(circles[0, :], key=lambda c: c[2])
    # radius = largest_circle[2]
    # diameter_px = 2 * radius
    # radius = int(radius)
    # center_x, center_y = largest_circle[0], largest_circle[1]
    # center_x, center_y = int(round(largest_circle[0])), int(round(largest_circle[1]))
    # circle_data = np.uint16(np.around(circles[0, 0]))
    # # åœ¨ROIä¸Šç»˜åˆ¶åœ†å’Œåœ†å¿ƒï¼ˆå¯è§†åŒ–è°ƒè¯•ï¼‰
    # cv2.circle(roi, (center_x, center_y), radius, (0, 255, 0), 2)  # ç»¿è‰²åœ†è¾¹ç•Œ
    # cv2.circle(roi, (center_x, center_y), 2, (0, 0, 255), 3)        # çº¢è‰²åœ†å¿ƒ
    # center = (circle_data[0], circle_data[1])
    # radius = circle_data[2]
    # diameter_px = float(radius * 2)

    # 4. ã€ç›´æ¥åœ¨ROIä¸Šç»˜å›¾ã€‘
    #    å› ä¸º roi æ˜¯åŸå›¾çš„ä¸€ä¸ªåˆ‡ç‰‡ï¼Œåœ¨è¿™é‡Œç»˜å›¾ä¼šç›´æ¥åæ˜ åˆ°æœ€ç»ˆçš„ä¸»å›¾åƒä¸Šã€‚
    # a) ç»˜åˆ¶æ£€æµ‹åˆ°çš„ç»¿è‰²åœ†ç¯
    # cv2.circle(roi, center, radius, (0, 255, 0), 2)
    # b) ç»˜åˆ¶çº¢è‰²çš„åœ†å¿ƒ
    # cv2.circle(roi, center, 3, (0, 0, 255), -1)
    # print(f"{diameter_px}")
    # 5. ã€ä¿æŒè¿”å›å€¼ä¸å˜ã€‘
    #    ä¸¥æ ¼æŒ‰ç…§æ‚¨çš„è¦æ±‚ï¼Œè¿”å› (ç›´å¾„, ç›´å¾„)
    # return diameter_px, diameter_px
    # å°†æ£€æµ‹åˆ°çš„åœ†è½¬æ¢ä¸ºæ•´æ•°åæ ‡

    # if len(circles) > 0:
    #     # æ‰¾åˆ°åŠå¾„æœ€å°çš„åœ†ï¼ˆå³ç›´å¾„æœ€å°çš„åœ†ï¼‰
    #     smallest_circle = max(circles, key=lambda c: c[2])  # c[2]æ˜¯åŠå¾„
    #     radius = smallest_circle[2]
    #     diameter_px = float(radius * 2)
    #     center_x, center_y = smallest_circle[0], smallest_circle[1]

    #     # åœ¨ROIä¸Šç»˜åˆ¶åœ†å’Œåœ†å¿ƒï¼ˆå¯è§†åŒ–è°ƒè¯•ï¼‰
    #     cv2.circle(roi, (center_x, center_y), radius, (0, 255, 0), 2)  # ç»¿è‰²åœ†è¾¹ç•Œ
    #     cv2.circle(roi, (center_x, center_y), 3, (0, 0, 255), -1)      # çº¢è‰²åœ†å¿ƒ

    #     print(f"æ£€æµ‹åˆ°çš„æœ€å°åœ†ç›´å¾„: {diameter_px}px")
    #     return diameter_px, diameter_px

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åœ†å½¢ï¼Œè¿”å›å€¼ä¹Ÿä¿æŒä¸å˜
    return None, None


# ==== æ¤­åœ†æ‰¾è½®å»“ ====
def get_ellipse_diameter_and_draw(roi, pixel_per_cm):
    """
    åœ¨ROIä¸­æ£€æµ‹ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ¤­åœ†ï¼Œç»˜åˆ¶å¹¶è¿”å›å…¶é•¿è½´é•¿åº¦ï¼ˆä½œä¸ºè¿‘ä¼¼ç›´å¾„ï¼‰ã€‚
    å¦‚æœæ¤­åœ†å¤ªå°ï¼Œåˆ™å°è¯•æ›´ç²¾ç¡®çš„æ£€æµ‹æ–¹æ³•ã€‚
    """
    if roi.size == 0:
        return None, None

    # 1. é¢„å¤„ç†ï¼šç°åº¦åŒ– + é«˜æ–¯æ¨¡ç³Š + äºŒå€¼åŒ–
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    binary = cv2.GaussianBlur(gray, (15, 15), 3)
    _, binary = cv2.threshold(binary, 0, 127, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # 2. æŸ¥æ‰¾è½®å»“å¹¶å°è¯•æ‹Ÿåˆæ¤­åœ†
    diameter = try_detect_ellipse(roi, binary)

    print(f"get_ellipse_diameter_and_draw: æˆ‘è¿›æ¥äº† ==== {diameter} ")
    # 3. å¦‚æœæ¤­åœ†æ£€æµ‹å¤±è´¥æˆ–å°ºå¯¸å¤ªå°ï¼Œå°è¯•æ›´ç²¾ç¡®çš„æ–¹æ³•
    if diameter is None or (diameter / pixel_per_cm <= 6):
        diameter = try_precise_detection(binary, pixel_per_cm)

    # 4. å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›ROIçš„å°ºå¯¸ä½œä¸ºé»˜è®¤å€¼
    if diameter is None:
        diameter = roi.shape[1]  # è¿”å›å®½åº¦ä½œä¸ºé»˜è®¤å€¼(æ›´åˆç†)
    cv2.imwrite("closed_canny.jpg", binary)
    return diameter, diameter


# ==== æ¤­åœ†æ‰¾è½®å»“ï¼Œåˆ¤æ–­æ–¹æ³• ====
def try_detect_ellipse(roi, binary):
    """å°è¯•æ£€æµ‹æ¤­åœ†å¹¶è¿”å›ç›´å¾„"""
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    for cnt in contours:
        if len(cnt) >= 5:  # æ‹Ÿåˆæ¤­åœ†è‡³å°‘éœ€è¦5ä¸ªç‚¹
            ellipse = cv2.fitEllipse(cnt)
            (center_x, center_y), (major_axis, minor_axis), angle = ellipse
            if not all(
                isinstance(val, (int, float)) and not np.isnan(val)
                for val in [center_x, center_y, major_axis, minor_axis]
            ):
                continue  # è·³è¿‡æ— æ•ˆçš„æ¤­åœ†
            # æ£€æŸ¥æ¤­åœ†æ˜¯å¦åœ¨ROIå†…
            if is_ellipse_within_bounds(
                roi, center_x, center_y, major_axis, minor_axis
            ):
                # ç»˜åˆ¶æ¤­åœ†å’Œä¸­å¿ƒç‚¹
                cv2.ellipse(roi, ellipse, (0, 255, 0), 2)
                cv2.circle(roi, (int(center_x), int(center_y)), 3, (0, 0, 255), -1)
                return float(major_axis)  # è¿”å›é•¿è½´é•¿åº¦ä½œä¸ºç›´å¾„

    return None


# ==== æ¤­åœ†æ‰¾è½®å»“ï¼Œåˆ¤æ–­æ–¹æ³• ====
def is_ellipse_within_bounds(roi, center_x, center_y, major_axis, minor_axis):
    """æ£€æŸ¥æ¤­åœ†æ˜¯å¦å®Œå…¨åœ¨ROIè¾¹ç•Œå†…"""
    center_x = float(center_x)
    center_y = float(center_y)
    major_axis = float(major_axis)
    minor_axis = float(minor_axis)

    x_min = max(0, int(center_x - major_axis / 2))
    y_min = max(0, int(center_y - minor_axis / 2))
    x_max = min(roi.shape[1], int(center_x + major_axis / 2))
    y_max = min(roi.shape[0], int(center_y + minor_axis / 2))

    return x_min >= 0 and y_min >= 0 and x_max <= roi.shape[1] and y_max <= roi.shape[0]


# ==== æ¤­åœ†æ‰¾è½®å»“ï¼Œä¸æ»¡è¶³æ—¶é‡æ–° ====
def try_precise_detection(binary, pixel_per_cm):
    """å°è¯•æ›´ç²¾ç¡®çš„å°ºå¯¸æ£€æµ‹æ–¹æ³•"""
    # å…ˆå°è¯•æ£€æµ‹åœ†å½¢
    # contour_w, contour_h = get_circle_diameter_and_draw(binary, False)
    # if contour_w and (contour_w/pixel_per_cm > 6):
    # return contour_w
    contour_w, contour_h = get_contour_dimensions(binary, False)
    # å¦‚æœåœ†å½¢å¤ªå°æˆ–æœªæ£€æµ‹åˆ°ï¼Œå°è¯•æ›´ç²¾ç¡®çš„å°ºå¯¸æµ‹é‡
    return contour_w


# ==== å›¾åƒå»ç•¸å˜ ====
def undistort_image(img, mtx, dist, alpha=1.0):
    """
    å¯¹è¾“å…¥å›¾åƒè¿›è¡Œå»ç•¸å˜å¤„ç†ã€‚

    å‚æ•°ï¼š
    - img: è¾“å…¥å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
    - mtx: ç›¸æœºå†…å‚çŸ©é˜µ
    - dist: ç•¸å˜ç³»æ•°
    - alpha: å»ç•¸å˜åå›¾åƒçš„ç¼©æ”¾å‚æ•°ï¼ŒèŒƒå›´[0,1]
             0è¡¨ç¤ºè£å‰ªå»é»‘è¾¹ï¼Œ1è¡¨ç¤ºä¿ç•™å…¨éƒ¨åŒºåŸŸå¯èƒ½æœ‰é»‘è¾¹

    è¿”å›ï¼š
    - å»ç•¸å˜ä¸”è£å‰ªåçš„å›¾åƒ
    """
    h, w = img.shape[:2]
    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), alpha, (w, h))

    # å»ç•¸å˜
    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)

    # è£å‰ªROIåŒºåŸŸ
    # x, y, w_roi, h_roi = roi
    # dst_cropped = dst[y:y+h_roi, x:x+w_roi]
    # filename = time.strftime("%Y%m%d_%H%M%S") + "dst.jpg"
    # cv2.imwrite(filename, dst_cropped)
    return dst  # , newcameramtx, roi


# ==== å›¾åƒå»ç•¸å˜ï¼Œåˆå§‹åŒ–å…ˆè·å–å‚æ•° ====
def init_undistort_maps(mtx, dist, image_size, alpha=1.0):
    """
    åˆå§‹åŒ–å»ç•¸å˜æ˜ å°„è¡¨ï¼ˆåªè°ƒç”¨ä¸€æ¬¡ï¼‰

    å‚æ•°ï¼š
    - mtx: ç›¸æœºå†…å‚
    - dist: ç•¸å˜ç³»æ•°
    - image_size: (w, h)ï¼Œå›¾åƒåˆ†è¾¨ç‡
    - alpha: ä¿ç•™å›¾åƒæ¯”ä¾‹ï¼ˆ0 = è£å‰ªï¼Œ1 = ä¿ç•™é»‘è¾¹ï¼‰

    è¿”å›ï¼š
    - map1, map2: æ˜ å°„çŸ©é˜µï¼Œç”¨äºå¿«é€Ÿ remap
    """
    newcameramtx, _ = cv2.getOptimalNewCameraMatrix(mtx, dist, image_size, alpha)
    map1, map2 = cv2.initUndistortRectifyMap(
        mtx, dist, None, newcameramtx, image_size, cv2.CV_16SC2
    )
    return map1, map2


# ==== å›¾åƒå»ç•¸å˜ï¼Œå†çŸ«æ­£ ====
def undistort_image_fast(img, map1, map2):
    """
    ä½¿ç”¨é¢„è®¡ç®—çš„æ˜ å°„è¡¨è¿›è¡Œå¿«é€Ÿå›¾åƒå»ç•¸å˜
    """
    return cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR)


# ==== åœ¨å›¾åƒä¸Šç»˜åˆ¶åŠé€æ˜æ£‹ç›˜ ====
def draw_checkerboard(image, cols=7, rows=8, alpha=0.3, color=(255, 255, 255)):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶åŠé€æ˜æ£‹ç›˜ã€‚
    :param image: è¾“å…¥å›¾åƒ
    :param cols: åˆ—æ•°
    :param rows: è¡Œæ•°
    :param alpha: æ£‹ç›˜åŠé€æ˜åº¦
    :param color: æ£‹ç›˜é¢œè‰² (BGR)
    """
    h, w = image.shape[:2]
    cell_w = w // cols
    cell_h = h // rows
    grid = np.zeros_like(image)

    for i in range(rows):
        for j in range(cols):
            if (i + j) % 2 == 0:
                top_left = (j * cell_w, i * cell_h)
                bottom_right = ((j + 1) * cell_w, (i + 1) * cell_h)
                cv2.rectangle(grid, top_left, bottom_right, color, -1)

    overlay = cv2.addWeighted(image, 1.0, grid, alpha, 0)
    return overlay


# ==== è®¡ç®—å®é™…åƒç´ æ¯” ====
def compute_pixel_per_cm(src_pts, real_width_cm, real_height_cm):
    """
    è®¡ç®—æ¯å˜ç±³åƒç´ æ•°ï¼ˆåƒç´ å¯†åº¦ï¼‰ã€‚

    å‚æ•°:
        src_pts: å››ä¸ªè§’ç‚¹åƒç´ åæ ‡ï¼Œé¡ºåºä¸º [å·¦ä¸Š, å³ä¸Š, å³ä¸‹, å·¦ä¸‹]
        real_width_cm: å®é™…å®½åº¦ (å•ä½: cm)
        real_height_cm: å®é™…é«˜åº¦ (å•ä½: cm)

    è¿”å›:
        å¹³å‡æ¯å˜ç±³çš„åƒç´ æ•°é‡ (float)
    """
    # è®¡ç®—åƒç´ è·ç¦»
    ref_width_px = np.linalg.norm(
        np.array(src_pts[1]) - np.array(src_pts[0])
    )  # å®½åº¦ï¼ˆä¸Šè¾¹ï¼‰
    ref_height_px = np.linalg.norm(
        np.array(src_pts[3]) - np.array(src_pts[0])
    )  # é«˜åº¦ï¼ˆå·¦è¾¹ï¼‰

    # è®¡ç®—æ°´å¹³æ–¹å‘å’Œå‚ç›´æ–¹å‘çš„åƒç´ å¯†åº¦
    pixel_per_cm_w = ref_width_px / real_width_cm
    pixel_per_cm_h = ref_height_px / real_height_cm

    # å–å¹³å‡æ›´ç¨³å®š
    pixel_per_cm = (pixel_per_cm_w + pixel_per_cm_h) / 2.0
    return pixel_per_cm


# ==== é€è§†å˜æ¢ ====
def compute_perspective_transform(
    img, src_pts, real_width_cm, real_height_cm, save_result=False
):
    """
    æ‰§è¡Œé€è§†å˜æ¢ï¼Œå¹¶è¿”å›å˜æ¢ç»“æœä¸åƒç´ å¯†åº¦ã€‚

    å‚æ•°:
        img: è¾“å…¥å›¾åƒ (numpy.ndarray)
        src_pts: å››ä¸ªå‚è€ƒç‚¹åæ ‡ (é¡ºåºï¼šå·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹)
        real_width_cm: å‚è€ƒåŒºåŸŸçš„å®é™…å®½åº¦ï¼ˆcmï¼‰
        real_height_cm: å‚è€ƒåŒºåŸŸçš„å®é™…é«˜åº¦ï¼ˆcmï¼‰
        save_result: æ˜¯å¦ä¿å­˜è½¬æ¢åçš„å›¾åƒä¸ºæ–‡ä»¶ï¼ˆé»˜è®¤ä¿å­˜ï¼‰

    è¿”å›:
        M: é€è§†å˜æ¢çŸ©é˜µ
        output_width: å˜æ¢åå›¾åƒå®½åº¦ï¼ˆpxï¼‰
        output_height: å˜æ¢åå›¾åƒé«˜åº¦ï¼ˆpxï¼‰
        pixel_per_cm: æ¯å˜ç±³å¯¹åº”çš„åƒç´ æ•°ï¼ˆfloatï¼‰
        warped: é€è§†å˜æ¢åçš„å›¾åƒï¼ˆnumpy.ndarrayï¼‰
    """
    if img is None:
        print("âŒ å›¾åƒä¸ºç©ºï¼Œæ— æ³•æ‰§è¡Œé€è§†å˜æ¢")
        return None, 0, 0, 0, None
    h, w = img.shape[:2]
    img_copy = img.copy()
    src_pts = np.array(src_pts, dtype=np.float32)

    # 1. è®¡ç®—åƒç´ å¯†åº¦
    pixel_per_cm = compute_pixel_per_cm(src_pts, real_width_cm, real_height_cm)

    # 2. è®¡ç®—è¾“å‡ºå›¾åƒå¤§å°ï¼ˆåƒç´ ï¼‰
    output_width = int(real_width_cm * pixel_per_cm)
    output_height = int(real_height_cm * pixel_per_cm)

    # 3. å®šä¹‰ç›®æ ‡å››è§’ç‚¹
    dst_pts = np.array(
        [[0, 0], [output_width, 0], [output_width, output_height], [0, output_height]],
        dtype=np.float32,
    )

    # 4. è·å–é€è§†çŸ©é˜µ
    M = cv2.getPerspectiveTransform(src_pts, dst_pts)

    # 5. æ‰§è¡Œé€è§†å˜æ¢
    warped = cv2.warpPerspective(img_copy, M, (output_width, output_height))

    # 6. ä¿å­˜ç»“æœ
    if save_result:
        filename = time.strftime("%Y%m%d_%H%M%S") + "_warped.jpg"
        cv2.imwrite(filename, warped)
        print(f"âœ… å·²ä¿å­˜é€è§†å›¾ï¼š{filename}")

    return M, output_width, output_height, pixel_per_cm, warped


# ==== é€è§†å˜æ¢ å°‘å‚æ•°====
def perspective_transform(img, src_pts, dst_pts, output_width, output_height):
    """
    æ‰§è¡Œé€è§†å˜æ¢ï¼Œå¹¶è¿”å›å˜æ¢ç»“æœä¸åƒç´ å¯†åº¦ã€‚

    å‚æ•°:
        img: è¾“å…¥å›¾åƒ (numpy.ndarray)
        src_pts: å››ä¸ªå‚è€ƒç‚¹åæ ‡ (é¡ºåºï¼šå·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹)
        real_width_cm: å‚è€ƒåŒºåŸŸçš„å®é™…å®½åº¦ï¼ˆcmï¼‰
        real_height_cm: å‚è€ƒåŒºåŸŸçš„å®é™…é«˜åº¦ï¼ˆcmï¼‰
        save_result: æ˜¯å¦ä¿å­˜è½¬æ¢åçš„å›¾åƒä¸ºæ–‡ä»¶ï¼ˆé»˜è®¤ä¿å­˜ï¼‰

    è¿”å›:
        M: é€è§†å˜æ¢çŸ©é˜µ
        output_width: å˜æ¢åå›¾åƒå®½åº¦ï¼ˆpxï¼‰
        output_height: å˜æ¢åå›¾åƒé«˜åº¦ï¼ˆpxï¼‰
        pixel_per_cm: æ¯å˜ç±³å¯¹åº”çš„åƒç´ æ•°ï¼ˆfloatï¼‰
        warped: é€è§†å˜æ¢åçš„å›¾åƒï¼ˆnumpy.ndarrayï¼‰
    """
    if img is None:
        print("âŒ å›¾åƒä¸ºç©ºï¼Œæ— æ³•æ‰§è¡Œé€è§†å˜æ¢")
        return None, 0, 0, 0, None
    h, w = img.shape[:2]
    img_copy = img.copy()
    src_pts = np.array(src_pts, dtype=np.float32)

    # 4. è·å–é€è§†çŸ©é˜µ
    M = cv2.getPerspectiveTransform(src_pts, dst_pts)

    # 5. æ‰§è¡Œé€è§†å˜æ¢
    warped = cv2.warpPerspective(img_copy, M, (output_width, output_height))

    return warped


# ==== é€è§†å˜æ¢ å°‘å‚æ•°====
def perspective_homography(img, src_pts, dst_pts, output_width, output_height):
    """
    æ‰§è¡Œé€è§†å˜æ¢ï¼Œå¹¶è¿”å›å˜æ¢ç»“æœä¸åƒç´ å¯†åº¦ã€‚

    å‚æ•°:
        img: è¾“å…¥å›¾åƒ (numpy.ndarray)
        src_pts: å››ä¸ªå‚è€ƒç‚¹åæ ‡ (é¡ºåºï¼šå·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹)
        real_width_cm: å‚è€ƒåŒºåŸŸçš„å®é™…å®½åº¦ï¼ˆcmï¼‰
        real_height_cm: å‚è€ƒåŒºåŸŸçš„å®é™…é«˜åº¦ï¼ˆcmï¼‰
        save_result: æ˜¯å¦ä¿å­˜è½¬æ¢åçš„å›¾åƒä¸ºæ–‡ä»¶ï¼ˆé»˜è®¤ä¿å­˜ï¼‰

    è¿”å›:
        M: é€è§†å˜æ¢çŸ©é˜µ
        output_width: å˜æ¢åå›¾åƒå®½åº¦ï¼ˆpxï¼‰
        output_height: å˜æ¢åå›¾åƒé«˜åº¦ï¼ˆpxï¼‰
        pixel_per_cm: æ¯å˜ç±³å¯¹åº”çš„åƒç´ æ•°ï¼ˆfloatï¼‰
        warped: é€è§†å˜æ¢åçš„å›¾åƒï¼ˆnumpy.ndarrayï¼‰
    """
    if img is None:
        print("âŒ å›¾åƒä¸ºç©ºï¼Œæ— æ³•æ‰§è¡Œé€è§†å˜æ¢")
        return None, 0, 0, 0, None
    h, w = img.shape[:2]
    img_copy = img.copy()
    src_pts = np.array(src_pts, dtype=np.float32)

    # 4. è·å–é€è§†çŸ©é˜µ
    M, status = cv2.findHomography(src_pts, dst_pts)

    # 5. æ‰§è¡Œé€è§†å˜æ¢
    warped = cv2.warpPerspective(img_copy, M, (output_width, output_height))

    return warped


def standardize_image_for_display(img):
    """ç¡®ä¿å›¾åƒå¯ä»¥å®‰å…¨ç”¨äº cv2.imshow"""
    if img is None:
        print("âŒ è¾“å…¥å›¾åƒä¸º None")
        return None

    if not isinstance(img, np.ndarray):
        print(f"âŒ è¾“å…¥ä¸æ˜¯ np.ndarrayï¼Œè€Œæ˜¯ {type(img)}")
        return None

    if img.dtype in [np.float32, np.float64]:
        img = np.nan_to_num(img)
        img = np.clip(img, 0, 1) if img.max() <= 1 else np.clip(img, 0, 255)
        img = (img * 255).astype(np.uint8) if img.max() <= 1 else img.astype(np.uint8)
    elif img.dtype != np.uint8:
        img = img.astype(np.uint8)

    if img.ndim == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    elif img.ndim == 3 and img.shape[2] == 4:
        img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)

    return img


# ==== æ ¹æ®åå¤„ç†å¾—åˆ°çš„åæ ‡ï¼Œæ¥è¯†åˆ«å°ºå¯¸ï¼Œè¿”å›å°ºå¯¸ ====
def annotate_xywh(boxes, pixel_per_cm):
    x, y, w, h = boxes
    # æ¢ç®—å®é™…å°ºå¯¸ï¼ˆcmï¼‰
    actual_w = w / pixel_per_cm
    actual_h = h / pixel_per_cm
    return actual_w, actual_h


# ==== æ ¹æ®åå¤„ç†å¾—åˆ°çš„åæ ‡ï¼Œæ¥è¯†åˆ«å°ºå¯¸ï¼Œè¿”å›çš„å›¾ç‰‡ ====
def measure_and_annotate_xywh(img, boxes, pixel_per_cm):
    if img is None:
        print("âŒ å›¾åƒä¸ºç©ºï¼Œæ— æ³•æ ‡æ³¨å°ºå¯¸")
        return img
    x, y, w, h = boxes
    # æ¢ç®—å®é™…å°ºå¯¸ï¼ˆcmï¼‰
    actual_w = w / pixel_per_cm
    actual_h = h / pixel_per_cm

    # è¿˜åŸä¸ºå·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡
    x1 = int(x)
    y1 = int(y)
    x2 = int(x + w)
    y2 = int(y + h)
    print(
        f"[debug] type: {type(img)} shape: {getattr(img, 'shape', 'None')} dtype: {getattr(img, 'dtype', 'None')}"
    )
    # æ§åˆ¶å°è¾“å‡ºå®é™…å°ºå¯¸
    print(f"ğŸ“ ç›®æ ‡å°ºå¯¸: å®½ = {actual_w:.2f} cm, é«˜ = {actual_h:.2f} cm")
    # ç»˜åˆ¶æ£€æµ‹æ¡†å’Œå°ºå¯¸æ ‡æ³¨
    # cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    label_text = f"{actual_w:.1f}cm x {actual_h:.1f}cm"
    cv2.putText(
        img,
        label_text,
        (x2 - 20, y1 - 10),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.5,
        (0, 0, 255),
        1,
    )
    # cv2.imwrite(time.strftime("%Y%m%d_%H%M%S") + "output.jpg", img)
    return img


# ==== ç»˜åˆ¶é»‘ç™½æ ¼ ====
def draw_real_size_grid(
    image, grid_size_cm=1.0, color=(0, 255, 0), thickness=1, alpha=0.3, pixels_per_cm=40
):
    """
    ç»˜åˆ¶å®é™…å°ºå¯¸ç½‘æ ¼ã€‚
    :param image: è¾“å…¥å›¾åƒ
    :param grid_size_cm: æ¯æ ¼å®é™…å°ºå¯¸ï¼ˆcmï¼‰
    :param color: ç»˜åˆ¶é¢œè‰² (BGR æ ¼å¼)
    :param thickness: çº¿æ¡ç²—ç»†
    :param alpha: ç½‘æ ¼å åŠ çš„é€æ˜åº¦
    """
    h, w = image.shape[:2]
    grid_size_px = int(grid_size_cm * pixels_per_cm)

    # åˆ›å»ºç½‘æ ¼å±‚
    grid_layer = np.zeros_like(image)

    # ç»˜åˆ¶çºµå‘ç½‘æ ¼çº¿
    for x in range(0, w, grid_size_px):
        cv2.line(grid_layer, (x, 0), (x, h), color, thickness)

    # ç»˜åˆ¶æ¨ªå‘ç½‘æ ¼çº¿
    for y in range(0, h, grid_size_px):
        cv2.line(grid_layer, (0, y), (w, y), color, thickness)

    # åˆæˆ
    overlay = cv2.addWeighted(image, 1.0, grid_layer, alpha, 0)
    return overlay


# ==== å›¾ç‰‡å¤§å°è½¬æ¢ ====
def letterbox_image(image, size):
    iw, ih = image.size
    w, h = size
    scale = min(w / iw, h / ih)
    nw = int(iw * scale)
    nh = int(ih * scale)

    image = image.resize((nw, nh), Image.BICUBIC)
    new_image = Image.new("RGB", size, (128, 128, 128))
    new_image.paste(image, ((w - nw) // 2, (h - nh) // 2))
    # cv_image = np.array(image)
    # cv2.imshow("output2", cv_image)
    return new_image


# ==== è£å‰ªåæ ‡ ====
def clip_coords(boxes, img_shape):
    # Clip bounding xyxy bounding boxes to image shape (height, width)
    boxes[:, 0].clip(0, img_shape[1], out=boxes[:, 0])  # x1
    boxes[:, 1].clip(0, img_shape[0], out=boxes[:, 1])  # y1
    boxes[:, 2].clip(0, img_shape[1], out=boxes[:, 2])  # x2
    boxes[:, 3].clip(0, img_shape[0], out=boxes[:, 3])  # y2


# ==== æ˜¾ç¤ºçª—å£ ====
def show_in_moved_window(winname, img, x, y):
    cv2.namedWindow(winname)  # Create a named window
    cv2.moveWindow(winname, x, y)  # Move it to (x,y)
    cv2.imshow(winname, img)


def compute_3d_distance(
    camera_matrix, dist_coeffs, image_points, object_width_cm, object_height_cm
):
    # ç‰©ä½“åœ¨ä¸–ç•Œåæ ‡ä¸­çš„4ä¸ªç‚¹ï¼ˆå•ä½cmï¼‰ï¼ŒZ=0è¡¨ç¤ºåœ¨åŒä¸€ä¸ªå¹³é¢
    object_points = np.array(
        [
            [0, 0, 0],
            [object_width_cm, 0, 0],
            [object_width_cm, object_height_cm, 0],
            [0, object_height_cm, 0],
        ],
        dtype=np.float32,
    )

    # å›¾åƒä¸­å¯¹åº”è§’ç‚¹çš„åƒç´ åæ ‡
    image_points_np = np.array(image_points, dtype=np.float32)

    # æ±‚è§£ rvec, tvec
    success, rvec, tvec = cv2.solvePnP(
        object_points, image_points_np, camera_matrix, dist_coeffs
    )

    if not success:
        # raise ValueError("solvePnP è§£ç®—å¤±è´¥")
        return None, None, None, None

    # å¹³ç§»å‘é‡ tvec è¡¨ç¤ºç›®æ ‡åæ ‡ç³»åŸç‚¹åœ¨ç›¸æœºåæ ‡ç³»ä¸­çš„ä½ç½®
    X, Y, Z = tvec.flatten()
    distance = np.linalg.norm(tvec)

    print("ğŸ“Œ solvePnP è§£ç®—æˆåŠŸï¼š")
    print(f"X = {X:.2f} cm, Y = {Y:.2f} cm, Z = {Z:.2f} cm")
    print(f"âœ… ç›¸æœºä¸ç‰©ä½“ä¸­å¿ƒçš„è·ç¦»çº¦ä¸ºï¼š{distance:.2f} cm")
    return X, Y, Z, distance


# ==== æ ¹æ®è¾“å…¥å›¾åƒçš„å¤§å°å’ŒåŸå§‹å›¾åƒçš„å°ºå¯¸ï¼Œè°ƒæ•´è¾¹ç•Œæ¡†çš„ä½ç½®å’Œå¤§å°ã€‚ ====
def adjust_boxes(size, boxes, original_size):
    """
    æ ¹æ®è¾“å…¥å›¾åƒçš„å¤§å°å’ŒåŸå§‹å›¾åƒçš„å°ºå¯¸ï¼Œè°ƒæ•´è¾¹ç•Œæ¡†çš„ä½ç½®å’Œå¤§å°ã€‚

    Args:
        size (tuple): å½“å‰è¾“å…¥å›¾åƒçš„å°ºå¯¸ (å®½åº¦, é«˜åº¦)ã€‚
        result_boxes: æ£€æµ‹å‡ºçš„è¾¹ç•Œæ¡†ï¼Œæ ¼å¼ä¸º [x_center, y_center, width, height]ã€‚
        original_size (tuple): åŸå§‹å›¾åƒçš„å°ºå¯¸ (å®½åº¦, é«˜åº¦)ã€‚

    Returns:
        numpy.ndarray: è°ƒæ•´åçš„è¾¹ç•Œæ¡†ï¼Œæ ¼å¼ä¸º [x_min, y_min, x_max, y_max]ã€‚
    """
    img_width, img_height = size
    target_width, target_height = original_size
    # print(f"size======{size}")
    # print(f"original_size======{original_size}")
    # è·å–ç¼©æ”¾æ¯”ä¾‹å’Œå¡«å……
    gain = min(img_width / target_width, img_height / target_height)
    pad_w = round((img_width - target_width * gain) / 2 - 0.1)  # æ°´å¹³å¡«å……
    pad_h = round((img_height - target_height * gain) / 2 - 0.1)  # å‚ç›´å¡«å……
    # print(f"size======{gain}")
    # print(f"pad======{pad_w, pad_h}")
    # å°†ä¸­å¿ƒç‚¹ (cx, cy) + å®½é«˜ (w, h) è½¬æ¢ä¸º (x_min, y_min, x_max, y_max) çš„æ‰¹é‡æ“ä½œ
    boxes[:, 0] = (boxes[:, 0] - boxes[:, 2] / 2 - pad_w) / gain  # x_min
    boxes[:, 1] = (boxes[:, 1] - boxes[:, 3] / 2 - pad_h) / gain  # y_min
    boxes[:, 2] = boxes[:, 2] / gain  # w ç¼©æ”¾
    boxes[:, 3] = boxes[:, 3] / gain  # h ç¼©æ”¾
    # print(f"boxes=========={boxes}")
    return boxes


def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):
    # Rescale coords (xyxy) from img1_shape to img0_shape
    if ratio_pad is None:  # calculate from img0_shape
        gain = max(img1_shape) / max(img0_shape)  # gain  = old / new
        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (
            img1_shape[0] - img0_shape[0] * gain
        ) / 2  # wh padding
    else:
        gain = ratio_pad[0][0]
        pad = ratio_pad[1]

    coords[:, [0, 2]] -= pad[0]  # x padding
    coords[:, [1, 3]] -= pad[1]  # y padding
    coords[:, :4] /= gain
    clip_coords(coords, img0_shape)
    # print(f"coords==========", coords)
    # gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])
    # pad = (
    #     round((img1_shape[0] - img0_shape[0] * gain) / 2 - 0.1),
    #     round((img1_shape[1] - img0_shape[1] * gain) / 2 - 0.1),
    # )
    # # x, y, w, h = box[:4]
    # coords[:, 0] = (coords[:, 0] - coords[:, 2] / 2 - pad[0]) / gain  # x_center
    # coords[:, 1] = (coords[:, 1] - coords[:, 3] / 2 - pad[1]) / gain  # y_center
    # coords[:, 2] = coords[:, 2] / gain  # width
    # coords[:, 3] = coords[:, 3] / gain  # height
    return coords


def get_3d_point(camera_matrix, rvec, tvec, image_point, world_z=0.0):
    """
    å°†å›¾åƒä¸Šçš„ä¸€ä¸ª2Dç‚¹åæŠ•å½±åˆ°æŒ‡å®šZé«˜åº¦çš„ä¸–ç•Œåæ ‡å¹³é¢ä¸Šã€‚

    :param image_point: å›¾åƒä¸Šçš„2Dåƒç´ åæ ‡ (u, v)
    :param world_z: è¯¥ç‚¹æ‰€åœ¨å¹³é¢çš„ä¸–ç•ŒZåæ ‡ï¼Œé»˜è®¤ä¸º0ï¼ˆå¾®æ³¢ç‚‰åº•ç›˜ï¼‰
    :return: 3Dä¸–ç•Œåæ ‡ (X, Y, Z)
    """
    # 1. å°†æ—‹è½¬å‘é‡è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
    rotation_matrix, _ = cv2.Rodrigues(rvec)

    # 2. è®¡ç®—ç›¸æœºå¤–å‚çŸ©é˜µ [R|t]
    extrinsic_matrix = np.hstack((rotation_matrix, tvec))

    # 3. è®¡ç®—å®Œæ•´çš„æŠ•å½±çŸ©é˜µ P = K * [R|t]
    projection_matrix = camera_matrix @ extrinsic_matrix

    # 4. ä¸ºäº†æ±‚è§£ï¼Œæˆ‘ä»¬éœ€è¦å°† P åˆ†è§£
    # P = [p1, p2, p3, p4] where p_i are column vectors
    # u = (p1.T * X) / (p3.T * X)
    # v = (p2.T * X) / (p3.T * X)
    # where X = [Xw, Yw, Zw, 1].T is the world point in homogeneous coords.

    # æˆ‘ä»¬æœ‰ u, v, Zwï¼Œè¦æ±‚ Xw, Yw
    # æ•´ç†æ–¹ç¨‹ä¸º A * [Xw, Yw] = B çš„å½¢å¼
    u, v = image_point

    p1 = projection_matrix[:, 0]
    p2 = projection_matrix[:, 1]
    p3 = projection_matrix[:, 2]
    p4 = projection_matrix[:, 3]

    # æ„å»ºçŸ©é˜µ A å’Œ B
    A = np.zeros((2, 2))
    A[0, 0] = p1[0] - u * p3[0]
    A[0, 1] = p2[0] - u * p3[0]
    A[1, 0] = p1[1] - v * p3[1]
    A[1, 1] = p2[1] - v * p3[1]

    B = np.zeros((2, 1))
    B[0, 0] = u * (p3[2] * world_z + p4[2]) - (p1[2] * world_z + p4[0])
    B[1, 0] = v * (p3[2] * world_z + p4[2]) - (p2[2] * world_z + p4[1])

    # æ±‚è§£ [Xw, Yw]
    try:
        world_xy = np.linalg.solve(A, B)
        return np.array([world_xy[0, 0], world_xy[1, 0], world_z])
    except np.linalg.LinAlgError:
        print("æ— æ³•æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„ï¼Œè¯·æ£€æŸ¥ç›¸æœºå‚æ•°æˆ–è¾“å…¥ç‚¹ã€‚")
        return None
